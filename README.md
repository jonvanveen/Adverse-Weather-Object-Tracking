# Object Tracking in Adverse Weather Conditions
### By Jon Van Veen, Han Wang, Danica Fliss
### For the course CS 766: Computer Vision at the University of Wisconsin-Madison
![alt text](https://cdn.freelogovectors.net/wp-content/uploads/2019/09/University-of-Wisconsin-Madison-Logo.png)

## Motivation
Object tracking is fundamental for autonomous vehicles (AVs) to perform path planning and object avoidance. Datasets commonly used to train object tracking algorithms for AVs contain mostly video from clear, open-air environments, causing the models to fail in adverse weather conditions. Even with data available, the performance of these algorithms severely degrades in adverse weather. The inability to perform object detection and tracking in various weather conditions is therefore a major roadblock for the use of AVs. In this project, we investigate object tracking in adverse weather conditions. 

We compare three prominent models in the object detection literature: [YOLO](https://pjreddie.com/darknet/yolo/) ("You Only Look Once"), [IA-YOLO](https://arxiv.org/abs/2112.08088) ("Image Adaptive"), and R-CNN. These models are trained on the [BDD100k dataset](https://www.bdd100k.com/). 

## 

## Results

## Source Code
